# üöÑ Infocentre Temps R√©el SNCF

> üí° **Solution d'ing√©nierie de donn√©es temps r√©el pour la surveillance et l'analyse de la ponctualit√© et des alertes de service des trains SNCF (TGV, Intercit√©s, TER).**

## üåü Vue d'Ensemble

Ce projet met en place un **Infocentre SNCF en temps r√©el**, permettant de suivre et d‚Äôanalyser la circulation ferroviaire sur l‚Äôensemble du r√©seau. Les donn√©es brutes des flux GTFS-RT et SIRI sont transform√©es et enrichies pour produire des indicateurs cl√©s et des statistiques consolid√©es.

L‚Äôinfrastructure g√©n√®re automatiquement des **KPI temps r√©el** tels que :

- Nombre de trains actifs actuellement ou sur la derni√®re heure.
- Nombre de trains en retard et variation par rapport √† la journ√©e pr√©c√©dente.
- Retard moyen journalier et comparaison avec la moyenne historique.
- Nombre de gares actives et √©volution horaire.
- Taux de retard par jour, par type de train et par r√©gion.
- Retards g√©n√©r√©s et rattrap√©s par r√©gion, ainsi que leur corr√©lation avec l‚Äôheure de passage.
- .... etc

Les **analyses station** permettent de suivre :

- Le trafic quotidien (arriv√©es/d√©parts) et les trains en retard.
- Le taux de ponctualit√© et les retards moyens par gare.
- L‚Äôutilisation des quais et leur trafic total.

Toutes ces mesures sont accessibles via des vues et *materialized views* PostgreSQL, ce qui permet une **consultation rapide et dynamique** des indicateurs pour le reporting ou la visualisation en BI.

---

## üöÄ Architecture Technique

Le projet repose sur la pile technologique suivante, enti√®rement conteneuris√©e avec **Docker** :

| Couche | Outil | R√¥le |
| :--- | :--- | :--- |
| **Orchestration** | **Apache Airflow** | Planification et ex√©cution des workflows de collecte et de transformation (**DAGs**) des donn√©es temps r√©el et des r√©f√©rentiels. |
| **Stockage** | **PostgreSQL (PostGIS)** | Base de donn√©es relationnelle servant de **Data Warehouse** (`sncf_trips`) et de base de m√©tadonn√©es pour Airflow (`airflow`). Stocke les faits temps r√©el et les tables de dimensions (Gares, Trajets, G√©ographie). |
| **Visualisation (Actuel)** | **Pentaho Server** | Plateforme de Business Intelligence utilis√©e pour g√©n√©rer des rapports et des tableaux de bord. |
| **Visualisation (Cible)** | **Apache Superset** | Nouvelle plateforme de BI pour des tableaux de bord modernes et interactifs. |
| **Conteneurisation** | **Docker / Docker Compose** | Configuration et d√©ploiement de l'environnement de d√©veloppement et de production. |


---

## üîó Sources de Donn√©es

Les flux de donn√©es sont extraits des API Open Data de la SNCF et des r√©f√©rentiels g√©ographiques nationaux.

| Cat√©gorie | Source | Endpoint / R√©f√©rence |
| :--- | :--- | :--- |
| **Temps R√©el (Facts)** | GTFS-RT Trip Updates & Service Alerts (TU/SA) | `https://proxy.transport.data.gouv.fr/resource/sncf-gtfs-rt-trip-updates` |
| **Temps R√©el (Alternative)** | SIRI Estimated Timetable (ET Lite) | `https://proxy.transport.data.gouv.fr/resource/sncf-siri-lite-estimated-timetable` |
| **R√©f√©rentiel Trajets**| GTFS Th√©orique / NeTEx | `https://eu.ftp.opendatasoft.com/sncf/plandata/Export_OpenData_SNCF_GTFS_NewTripId.zip` |
| **R√©f√©rentiel Gares** | Liste des gares du R√©seau Ferr√© National | `https://ressources.data.sncf.com/explore/dataset/liste-des-gares/information/` |
| **R√©f√©rentiel G√©ographique** | Donn√©es INSEE (R√©gions, D√©p., Villes) | `https://www.data.gouv.fr/datasets/regions-departements-villes-et-villages-de-france-et-doutre-mer/` |

---

## üèóÔ∏è Structure du Projet


---

## ‚öôÔ∏è D√©marrage Rapide

Ce projet utilise Docker Compose pour orchestrer l'ensemble des services (Airflow, PostgreSQL, Pentaho, etc.).

### 1. Pr√©requis

* **Docker**
* **Docker Compose**

### 2. D√©marrage de l'environnement

1.  Cloner le d√©p√¥t :
    ```bash
    git clone #####
    cd #####
    ```
2. Configuration de l'environnement

Cr√©ez un fichier `.env` (√† partir du fichier template) √† la racine du projet pour d√©finir les variables d'environnement n√©cessaires au fonctionnement des services.

**Exemple des variables d'environnement critiques (fichier `.env`) :**

```env
# Configuration Airflow (M√©tadonn√©es)
AIRFLOW_USER=airflow
AIRFLOW_PASSWORD=airflow
AIRFLOW_DB=airflow
AIRFLOW_HOST=postgres

# Configuration PostgreSQL (Utilisateur/Base par d√©faut pour l'initialisation)
POSTGRES_USER=postgres
POSTGRES_PASSWORD=postgres
POSTGRES_DB=postgres

# Configuration Data Warehouse (DWH - Base de donn√©es des donn√©es SNCF)
DWH_HOST=postgres
DWH_USER=etl_user
DWH_PASSWORD=etl_password
DWH_DB=sncf_trips
DWH_PORT=5432

# Utilisateur Admin Airflow
AIRFLOW_ADMIN_USERNAME=airflow
AIRFLOW_ADMIN_PASSWORD=airflow
```

2.  Lancer la commande de votre script `run.sh` pour l'initialisation et le d√©marrage :
    ```bash
    ./run.sh
    # ou si vous utilisez docker-compose directement :
    # docker-compose up -d --build
    ```
3.  Attendre quelques minutes que tous les conteneurs soient op√©rationnels (v√©rifiez avec `docker ps`).

### 3. Acc√®s aux Interfaces

| Service | URL | Identifiants par D√©faut | Remarques |
| :--- | :--- | :--- | :--- |
| **Airflow UI** | `http://localhost:[8084 - Port Airflow UI]` | **User :** `[airflow_user]` / **Pass :** `[airflow_pass]` | Interface web pour g√©rer et monitorer les pipelines ETL et les t√¢ches en temps r√©el. |
| **PostgreSQL** | `[http://localhost:[8082 - Port Postgresql]/database]` | **User :** `[postgres_user]` / **Pass :** `[postgres_pass]` | Base de donn√©es relationnelle et spatiale (PostGIS) pour stocker les donn√©es du Data Warehouse. |
| **Pentaho Server (Actuel)** | `http://localhost:[8086 - Port Pentaho]` | Aucun identifiant de connexion n'est necessaire. | Serveur BI pour cr√©ation et publication de rapports et tableaux de bord. |
| **Superset (Futur)** |  | **User :** `[superset_user]` / **Pass :** `[superset_pass]` | Remplacera Pentaho pour la visualisation interactive et l‚Äôexploration des donn√©es. |


---



## ü§ù Contribution

TODO